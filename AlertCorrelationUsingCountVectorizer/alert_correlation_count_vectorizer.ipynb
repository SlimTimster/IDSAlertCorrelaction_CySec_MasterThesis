{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "\n",
    "from data_helper import load_data, load_true_labels, add_true_labels_to_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS - Change these to use different data from the dataset!\n",
    "\n",
    "# 1. santos | inet-firewall | dnsmasq.log\n",
    "path_santos = \"../../AIT_LD-v2/santos\"\n",
    "path_log_file = \"/gather/inet-firewall/logs/dnsmasq.log\"\n",
    "path_true_labels_file = \"/labels/inet-firewall/logs/dnsmasq.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Jan 14 00:07:10 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Jan 14 00:07:10 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Jan 14 00:07:27 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Jan 14 00:07:27 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Jan 14 00:07:27 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Jan 14 00:07:41 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Jan 14 00:07:41 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Jan 14 00:07:41 dnsmasq[14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0\n",
       "144  Jan 14 00:07:10 dnsmasq[14...\n",
       "145  Jan 14 00:07:10 dnsmasq[14...\n",
       "146  Jan 14 00:07:27 dnsmasq[14...\n",
       "147  Jan 14 00:07:27 dnsmasq[14...\n",
       "148  Jan 14 00:07:27 dnsmasq[14...\n",
       "149  Jan 14 00:07:41 dnsmasq[14...\n",
       "150  Jan 14 00:07:41 dnsmasq[14...\n",
       "151  Jan 14 00:07:41 dnsmasq[14..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the AIT log data set v2\n",
    "df_raw = load_data(path_santos + path_log_file)\n",
    "\n",
    "# Display the first few rows of the data set\n",
    "#df_raw.head(5)\n",
    "\n",
    "# Display the entries corresponding to attack (rows 144-151)\n",
    "df_raw.iloc[144:152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>labels</th>\n",
       "      <th>rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72</td>\n",
       "      <td>[dnsteal, attacker, dnstea...</td>\n",
       "      <td>{'dnsteal': ['dnsteal.doma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line                         labels                          rules\n",
       "0     1  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "1     2  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "2     3  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "3    50  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "4    51  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "5    52  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "6    53  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "7    54  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "8    55  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma...\n",
       "9    72  [dnsteal, attacker, dnstea...  {'dnsteal': ['dnsteal.doma..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load true labels from json\n",
    "df_true_labels = load_true_labels(path_santos + path_true_labels_file)\n",
    "\n",
    "df_true_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true labels to the dataset\n",
    "df_raw = add_true_labels_to_dataset(df_raw, df_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>true_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan 14 00:00:09 dnsmasq[14...</td>\n",
       "      <td>1</td>\n",
       "      <td>['dnsteal', 'attacker', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 14 00:00:09 dnsmasq[14...</td>\n",
       "      <td>1</td>\n",
       "      <td>['dnsteal', 'attacker', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan 14 00:00:09 dnsmasq[14...</td>\n",
       "      <td>1</td>\n",
       "      <td>['dnsteal', 'attacker', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan 14 00:00:23 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan 14 00:00:23 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0 true_type                         labels\n",
       "0  Jan 14 00:00:09 dnsmasq[14...         1  ['dnsteal', 'attacker', 'd...\n",
       "1  Jan 14 00:00:09 dnsmasq[14...         1  ['dnsteal', 'attacker', 'd...\n",
       "2  Jan 14 00:00:09 dnsmasq[14...         1  ['dnsteal', 'attacker', 'd...\n",
       "3  Jan 14 00:00:23 dnsmasq[14...       NaN                            NaN\n",
       "4  Jan 14 00:00:23 dnsmasq[14...       NaN                            NaN"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 275667 entries, 0 to 275666\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   0          275667 non-null  object\n",
      " 1   true_type  39426 non-null   object\n",
      " 2   labels     39426 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>true_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>275667</td>\n",
       "      <td>39426</td>\n",
       "      <td>39426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>207381</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Jan 14 11:22:17 dnsmasq[14...</td>\n",
       "      <td>1</td>\n",
       "      <td>['dnsteal', 'attacker', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>53</td>\n",
       "      <td>39426</td>\n",
       "      <td>38561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0 true_type                         labels\n",
       "count                          275667     39426                          39426\n",
       "unique                         207381         1                              7\n",
       "top     Jan 14 11:22:17 dnsmasq[14...         1  ['dnsteal', 'attacker', 'd...\n",
       "freq                               53     39426                          38561"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>true_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>275667</td>\n",
       "      <td>39426</td>\n",
       "      <td>39426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>207381</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Jan 14 11:22:17 dnsmasq[14...</td>\n",
       "      <td>1</td>\n",
       "      <td>['dnsteal', 'attacker', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>53</td>\n",
       "      <td>39426</td>\n",
       "      <td>38561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0 true_type                         labels\n",
       "count                          275667     39426                          39426\n",
       "unique                         207381         1                              7\n",
       "top     Jan 14 11:22:17 dnsmasq[14...         1  ['dnsteal', 'attacker', 'd...\n",
       "freq                               53     39426                          38561"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 0\n",
       "true_type    236241\n",
       "labels       236241\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68286"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "# 1. santos | inet-firewall | dnsmasq.log               duplicates: 68286, isnull: true_type: 236241, labels: 236241\n",
    "\n",
    "df_raw.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>true_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jan 14 00:00:23 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jan 14 00:00:23 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jan 14 00:00:23 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jan 14 00:00:23 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jan 14 00:00:23 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275644</th>\n",
       "      <td>Jan 17 23:39:13 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275645</th>\n",
       "      <td>Jan 17 23:39:13 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275653</th>\n",
       "      <td>Jan 17 23:39:13 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275654</th>\n",
       "      <td>Jan 17 23:39:13 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275660</th>\n",
       "      <td>Jan 17 23:44:37 dnsmasq[14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68286 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0 true_type labels\n",
       "11      Jan 14 00:00:23 dnsmasq[14...       NaN    NaN\n",
       "12      Jan 14 00:00:23 dnsmasq[14...       NaN    NaN\n",
       "13      Jan 14 00:00:23 dnsmasq[14...       NaN    NaN\n",
       "14      Jan 14 00:00:23 dnsmasq[14...       NaN    NaN\n",
       "18      Jan 14 00:00:23 dnsmasq[14...       NaN    NaN\n",
       "...                               ...       ...    ...\n",
       "275644  Jan 17 23:39:13 dnsmasq[14...       NaN    NaN\n",
       "275645  Jan 17 23:39:13 dnsmasq[14...       NaN    NaN\n",
       "275653  Jan 17 23:39:13 dnsmasq[14...       NaN    NaN\n",
       "275654  Jan 17 23:39:13 dnsmasq[14...       NaN    NaN\n",
       "275660  Jan 17 23:44:37 dnsmasq[14...       NaN    NaN\n",
       "\n",
       "[68286 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> Duplicates normal if logs are written quickly\n",
    "# TODO: investigate which lines are duplicated and how to treat them. e.g. combine them and keep info about count or keep them as they are\n",
    "\n",
    "df_raw[df_raw.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: For CountVectorizer we will remove duplicates #TODO: Test later if this is a good idea\n",
    "\n",
    "df_raw = df_raw.drop_duplicates()\n",
    "df_raw.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of true labels into benign and attack-related\n",
    "\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#sns.countplot(x=df_raw['true_type'])\n",
    "#plt.title(\"Label Distribution\")\n",
    "#plt.xticks(ticks=[0,1], labels=['Benign', 'Attack-related'])\n",
    "\n",
    "#for i in range(2):\n",
    "#    count = df_raw['true_type'].value_counts().values[i]\n",
    "#    plt.text(i, count, str(count), ha = 'center')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column name\n",
    "df_raw.columns = ['raw', 'true_type', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CountVectorizer to convert the raw text data into a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer() # Using \"english\" stop-words: 107431, without: 107431 #TODO: Test difference\n",
    "# TODO: Try max_df and min_df (to ignore words that appear often or rarely)\n",
    "vocab = vectorizer.fit(df_raw['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer vocabulary size:  107493\n",
      "['00' '000' '0001' ... 'zzzvm4py7ktn' 'zzzzbpkx08ybkoomdsplpwpznfwjp6'\n",
      " 'zzzzw7m']\n"
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer vocabulary size: \", vocab.vocabulary_.__len__())\n",
    "\n",
    "print(vocab.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Binary Classification (Benign vs Attack)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# LabelBinarizer to convert the true_type column into binary labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y = label_binarizer.fit_transform(\n",
    "    df_raw['true_type'].apply(lambda x: 1 if x == \"1\" else 0)\n",
    ").ravel()   # ravel() to flatten to 1D array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., nan, nan, nan], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['true_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<207381x107493 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3767438 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Feature Matrix X from Vectorizer\n",
    "X = vectorizer.transform(df_raw['raw'])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train, test and validation sets\n",
    "# 70% train, 10% validation, 20% test #TODO: Calculate if this is correct\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution in training set:\n",
      "Counter({0: 117766, 1: 27400})\n",
      "\n",
      "Class distribution in validation set:\n",
      "Counter({0: 16824, 1: 3914})\n",
      "\n",
      "Class distribution in test set:\n",
      "Counter({0: 33648, 1: 7829})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "print(\"\\nClass distribution in validation set:\")\n",
    "print(Counter(y_val))\n",
    "\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "print(Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional garbage collection:\n",
    "import gc\n",
    "\n",
    "del X_temp, y_temp, df_raw, df_true_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECIDE IF TRAINING SHOULD BE DONE OR IF CLASSIFIERS SHOULD BE LOADED FROM DISK INSTEAD\n",
    "run_training = False\n",
    "\n",
    "# Save the trained classifiers to disk, OVERWRITING existing ones!\n",
    "save_trained_classifiers = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----Training Logistic Regression -----\n",
      "Validation Results for Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      1.00      1.00      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      1.00      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16823     1]\n",
      " [    1  3913]]\n",
      "\n",
      "\n",
      "-----Training Random Forest -----\n",
      "Validation Results for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      1.00      1.00      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      1.00      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16824     0]\n",
      " [    1  3913]]\n",
      "\n",
      "\n",
      "-----Training Naive Bayes -----\n",
      "Validation Results for Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      0.99      0.99      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      0.99      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16824     0]\n",
      " [   54  3860]]\n",
      "\n",
      "\n",
      "-----Training SVM -----\n",
      "Validation Results for SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      1.00      1.00      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      1.00      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16823     1]\n",
      " [    2  3912]]\n",
      "\n",
      "\n",
      "-----Training Decision Tree -----\n",
      "Validation Results for Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      1.00      1.00      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      1.00      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16824     0]\n",
      " [    1  3913]]\n",
      "\n",
      "\n",
      "-----Training KNN -----\n",
      "Validation Results for KNN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      0.99      0.99      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      0.99      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16820     4]\n",
      " [   43  3871]]\n",
      "\n",
      "\n",
      "-----Training MLP -----\n",
      "Validation Results for MLP:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      1.00      1.00      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      1.00      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16824     0]\n",
      " [    0  3914]]\n",
      "\n",
      "\n",
      "-----Training AdaBoost -----\n",
      "Validation Results for AdaBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16824\n",
      "           1       1.00      1.00      1.00      3914\n",
      "\n",
      "    accuracy                           1.00     20738\n",
      "   macro avg       1.00      1.00      1.00     20738\n",
      "weighted avg       1.00      1.00      1.00     20738\n",
      "\n",
      "Confusion Matrix for {name}: \n",
      "[[16823     1]\n",
      " [    1  3913]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Run Binary Classifiers\n",
    "  \n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    #\"XGBoost\": XGBClassifier(use_label_encoder=False),\n",
    "    \"MLP\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "if(run_training):\n",
    "    for name, classifier in classifiers.items():\n",
    "        print(\"\\n\\n-----Training\", name, \"-----\")\n",
    "\n",
    "        # Train\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = classifier.predict(X_val)\n",
    "\n",
    "        # Evaluate\n",
    "        print(f\"Validation Results for {name}:\\n\", classification_report(y_val, y_pred))\n",
    "        print(\"Confusion Matrix for {name}: \")\n",
    "        print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Save the trained classifiers and vectorizer to disk\n",
    "if(run_training and save_trained_classifiers):\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "\n",
    "    for name, classifier in classifiers.items():\n",
    "        filename = f\"models/{name.replace(' ', '_')}.joblib\"\n",
    "        joblib.dump(classifier, filename)\n",
    "    \n",
    "    joblib.dump(vectorizer, \"models/vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not run_training):\n",
    "    classifiers = {}\n",
    "    for name in classifiers.keys():\n",
    "        classifiers[name] = joblib.load(f\"models/{name.replace(\" \", \"_\")}.joblib\")\n",
    "    \n",
    "    vectorizer = joblib.load(\"models/vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x107493 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results from Logistic Regression:\n",
      "\n",
      "Message: DHCP REQUEST received from 192.168.1.100\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Message: Multiple failed login attempts from IP 10.0.0.5\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Message: DNS query www.example.com from 192.168.1.50\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Results from Random Forest:\n",
      "\n",
      "Message: DHCP REQUEST received from 192.168.1.100\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.960, attack: 0.040\n",
      "\n",
      "Message: Multiple failed login attempts from IP 10.0.0.5\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Message: DNS query www.example.com from 192.168.1.50\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Results from Naive Bayes:\n",
      "\n",
      "Message: DHCP REQUEST received from 192.168.1.100\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.783, attack: 0.217\n",
      "\n",
      "Message: Multiple failed login attempts from IP 10.0.0.5\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.973, attack: 0.027\n",
      "\n",
      "Message: DNS query www.example.com from 192.168.1.50\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Results from SVM:\n",
      "This classifier does not support predict_proba().\n",
      "\n",
      "Results from Decision Tree:\n",
      "\n",
      "Message: DHCP REQUEST received from 192.168.1.100\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Message: Multiple failed login attempts from IP 10.0.0.5\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Message: DNS query www.example.com from 192.168.1.50\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Results from KNN:\n",
      "\n",
      "Message: DHCP REQUEST received from 192.168.1.100\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Message: Multiple failed login attempts from IP 10.0.0.5\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Message: DNS query www.example.com from 192.168.1.50\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Results from MLP:\n",
      "\n",
      "Message: DHCP REQUEST received from 192.168.1.100\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.915, attack: 0.085\n",
      "\n",
      "Message: Multiple failed login attempts from IP 10.0.0.5\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.997, attack: 0.003\n",
      "\n",
      "Message: DNS query www.example.com from 192.168.1.50\n",
      "Prediction: normal\n",
      "Probability scores: normal: 1.000, attack: 0.000\n",
      "\n",
      "Results from AdaBoost:\n",
      "\n",
      "Message: DHCP REQUEST received from 192.168.1.100\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.733, attack: 0.267\n",
      "\n",
      "Message: Multiple failed login attempts from IP 10.0.0.5\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.740, attack: 0.260\n",
      "\n",
      "Message: DNS query www.example.com from 192.168.1.50\n",
      "Prediction: normal\n",
      "Probability scores: normal: 0.738, attack: 0.262\n"
     ]
    }
   ],
   "source": [
    "# Manually check a few hardcoded example messages from the validation set\n",
    "\n",
    "def predict_message(message, classifier):\n",
    "    # Transform the new message using same vectorizer\n",
    "    message_vectorized = vectorizer.transform([message])\n",
    "    # Make prediction\n",
    "    prediction = classifier.predict(message_vectorized)[0]\n",
    "    # Get probability scores\n",
    "    prob = classifier.predict_proba(message_vectorized)[0]\n",
    "    return prediction, prob\n",
    "\n",
    "# A few test messages from the validation set \n",
    "test_messages = [\n",
    "    \"DHCP REQUEST received from 192.168.1.100\",  # normal message example\n",
    "    \"Multiple failed login attempts from IP 10.0.0.5\",  # potential attack example\n",
    "    \"DNS query www.example.com from 192.168.1.50\"  # another normal message example\n",
    "]\n",
    "\n",
    "# Test each message with each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nResults from {name}:\")\n",
    "\n",
    "    if(not hasattr(clf, \"predict_proba\")):\n",
    "        print(\"This classifier does not support predict_proba().\")\n",
    "        continue\n",
    "\n",
    "    for msg in test_messages:\n",
    "        prediction, probabilities = predict_message(msg, clf)\n",
    "        print(f\"\\nMessage: {msg}\")\n",
    "        print(f\"Prediction: {'attack' if prediction == 1 else 'normal'}\")\n",
    "        print(f\"Probability scores: normal: {probabilities[0]:.3f}, attack: {probabilities[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "MPS available: False\n"
     ]
    }
   ],
   "source": [
    "# Troubleshooting torch installation\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5973, 0.0086, 0.2944],\n",
      "        [0.0028, 0.6524, 0.6644],\n",
      "        [0.4380, 0.2283, 0.6385],\n",
      "        [0.0467, 0.1260, 0.8122],\n",
      "        [0.9741, 0.1510, 0.3118]])\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "\n",
    "# Choose Hardware, Cuda uses GPU\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Test PyTorch Model using their tutorial (mainly to test installation & hardware)\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = nn_model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class, (currently pytorch default)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(1000, 11005),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=11005, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Create model instance\n",
    "nn_model = NeuralNetwork().to(device)\n",
    "print(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24050</td>\n",
       "      <td>24050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>['dnsteal', 'attacker', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>24050</td>\n",
       "      <td>24050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       true_type                         labels\n",
       "count      24050                          24050\n",
       "unique         1                              1\n",
       "top            1  ['dnsteal', 'attacker', 'd...\n",
       "freq       24050                          24050"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_o_h.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Columns: 11007 entries, timestamp to 9_msgt\n",
      "dtypes: datetime64[ns](1), float64(11001), int64(3), object(2)\n",
      "memory usage: 8.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_with_o_h.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: ['1' nan]\n",
      "X tensor shape: torch.Size([1000, 11005])\n",
      "y tensor shape: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing pipeline\n",
    "# Only take first 1000 rows for now (memory limit and speed up)\n",
    "X = df_with_o_h.iloc[0:1000].drop([\"true_type\", \"labels\"], axis=1)\n",
    "\n",
    "# Ensure all column names are strings\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "# Convert datetime columns to numerical features\n",
    "for col in X.select_dtypes(include=['datetime64']).columns:\n",
    "    X[col] = X[col].astype('int64')  # Convert datetime to timestamp\n",
    "\n",
    "# Drop any remaining non-numeric columns\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Prepare labels\n",
    "y = df_with_o_h.iloc[0:1000][\"true_type\"]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "# Print some information\n",
    "print(\"Unique labels:\", label_encoder.classes_)\n",
    "print(\"X tensor shape:\", X_tensor.shape)\n",
    "print(\"y tensor shape:\", y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1000x11005 and 1000x11005)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m logits \u001b[38;5;241m=\u001b[39m nn_model(X_tensor\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[107], line 16\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m---> 16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_relu_stack(x)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\timgi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1000x11005 and 1000x11005)"
     ]
    }
   ],
   "source": [
    "logits = nn_model(X_tensor.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
